{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datasets import Dataset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_txt = 'data/cadec/text/'\n",
    "root_ann = 'data/cadec/original/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(fn):\n",
    "    med, i = re.findall(r'(\\w+)\\.(\\d+)\\.txt', fn)[0]\n",
    "    i = int(i)\n",
    "\n",
    "    with open(os.path.join(root_txt, fn), 'r') as infile:\n",
    "        text = infile.readlines()\n",
    "        text = ''.join(text)\n",
    "    with open(os.path.join(root_ann, fn.replace('txt', 'ann')), 'r') as infile:\n",
    "        annotations = infile.readlines()\n",
    "        annotations = [l.strip() for l in annotations if not l.startswith('#')]\n",
    "    return i, med, text, annotations\n",
    "    \n",
    "\n",
    "def parse_annotations(lines):\n",
    "    annots = {}\n",
    "    for i in range(len(lines)):\n",
    "        annots[i] = {}\n",
    "        entity = re.findall(r'(Finding|ADR|Drug|Disease|Symptom) ([\\d; ]+)\\t(.*)$', \n",
    "                            lines[i])[0]\n",
    "        annots[i]['ner'] = entity[0]\n",
    "        boundaries = entity[1].split(';')\n",
    "        boundaries = [[int(bb) for bb in b.split()] for b in boundaries]\n",
    "        annots[i]['boundaries'] = boundaries\n",
    "        annots[i]['text'] = entity[2]\n",
    "    return annots\n",
    "\n",
    "\n",
    "def get_current_annot(annots, idx, start):\n",
    "    if idx >= len(annots):\n",
    "        return idx - 1\n",
    "    boundaries = annots[idx]['boundaries']\n",
    "    if start > boundaries[-1][-1]:\n",
    "        return get_current_annot(annots, idx+1, start)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def print_tags_tokens(data):\n",
    "    tokens = data['tokens']\n",
    "    tags = data['ner']\n",
    "    line1 = \"\"\n",
    "    line2 = \"\"\n",
    "    for word, label in zip(tokens, tags):\n",
    "        max_length = max(len(word), len(label))\n",
    "        line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "        line2 += label + \" \" * (max_length - len(label) + 1)\n",
    "    print(line1)\n",
    "    print(line2)\n",
    "\n",
    "\n",
    "def get_IOB_tags(text: str, annotations: dict):\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "    if len(annotations) == 0:\n",
    "        return tokens, ['O' for _ in tokens]\n",
    "    offset = 0\n",
    "    idx = 0\n",
    "    tags = []\n",
    "    text_tmp = text\n",
    "    for token in tokens:\n",
    "        span = np.asarray(re.search(re.escape(token), text_tmp).span())\n",
    "        idx = get_current_annot(annotations, idx, span[0] + offset)\n",
    "        boundaries = annotations[idx]['boundaries']\n",
    "        found = False\n",
    "        for i, (start, end) in enumerate(boundaries):\n",
    "            if (span[0] + offset >= start) and (span[1] + offset <= end):\n",
    "                prefix = 'B-'\n",
    "                if i > 0 or span[0] + offset > start:\n",
    "                    prefix = 'I-'\n",
    "                tags.append(prefix + annotations[idx]['ner'])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            tags.append('O')\n",
    "        offset += span[1]\n",
    "        text_tmp = text_tmp[span[1]:]\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing data into the desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for fn in os.listdir(root_txt):\n",
    "    i, med, text, annotations = read_files(fn)\n",
    "    annots = parse_annotations(annotations)\n",
    "    tokens, tags = get_IOB_tags(text, annots)\n",
    "    if med not in data.keys():\n",
    "        data[med] = {}\n",
    "    data[med][i] = {\n",
    "        'tokens': tokens, 'ner': tags\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {}\n",
    "idx = 0\n",
    "tt_split = 0.8 # train/test split - should maybe add validation?\n",
    "for v in data.values():\n",
    "    for vv in v.values():\n",
    "        raw_data[idx] = vv\n",
    "        idx += 1\n",
    "\n",
    "indices = np.arange(len(raw_data))\n",
    "np.random.shuffle(indices)\n",
    "train_idx = indices[:int(tt_split * len(indices))]\n",
    "test_idx = indices[int(tt_split * len(indices)):]\n",
    "\n",
    "data_split = {'train': {}, 'test': {}}\n",
    "for idx in train_idx:\n",
    "    for k in raw_data[idx].keys():\n",
    "        if k not in data_split['train']:\n",
    "            data_split['train'][k] = []\n",
    "        data_split['train'][k].append(raw_data[idx][k])\n",
    "\n",
    "for idx in test_idx:\n",
    "    for k in raw_data[idx].keys():\n",
    "        if k not in data_split['test']:\n",
    "            data_split['test'][k] = []\n",
    "        data_split['test'][k].append(raw_data[idx][k]) \n",
    "\n",
    "datasets = {k: Dataset.from_dict(data_split[k]) for k in data_split.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
