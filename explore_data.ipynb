{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_txt = 'data/cadec/text/'\n",
    "root_ann = 'data/cadec/original/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(fn):\n",
    "    med, i = re.findall(r'(\\w+)\\.(\\d+)\\.txt', fn)[0]\n",
    "    print(med, i)\n",
    "    i = int(i)\n",
    "\n",
    "    with open(os.path.join(root_txt, fn), 'r') as infile:\n",
    "        text = infile.readlines()\n",
    "        text = ''.join(text)\n",
    "    with open(os.path.join(root_ann, fn.replace('txt', 'ann')), 'r') as infile:\n",
    "        annotations = infile.readlines()\n",
    "        annotations = [l.strip() for l in annotations if not l.startswith('#')]\n",
    "    return i, med, text, annotations\n",
    "    \n",
    "\n",
    "def parse_annotations(lines):\n",
    "    annots = {}\n",
    "    for i in range(len(lines)):\n",
    "        annots[i] = {}\n",
    "        entity = re.findall(r'(Finding|ADR|Drug|Disease|Symptom) ([\\d; ]+)\\t(.*)$', \n",
    "                            lines[i])[0]\n",
    "        annots[i]['ner'] = entity[0]\n",
    "        boundaries = entity[1].split(';')\n",
    "        boundaries = [[int(bb) for bb in b.split()] for b in boundaries]\n",
    "        annots[i]['boundaries'] = boundaries\n",
    "        annots[i]['text'] = entity[2]\n",
    "    return annots\n",
    "\n",
    "\n",
    "def get_current_annot(annots, idx, start):\n",
    "    if idx > len(annots):\n",
    "        return idx - 1\n",
    "    boundaries = annots[idx]['boundaries']\n",
    "    if start > boundaries[-1][-1]:\n",
    "        return get_current_annot(annots, idx+1, start)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IOB_tags(text: str, annotations: dict):\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "    if len(annotations) == 0:\n",
    "        return tokens, ['O' for _ in tokens]\n",
    "    offset = 0\n",
    "    idx = 0\n",
    "    tags = []\n",
    "    text_tmp = text\n",
    "    for token in tokens:\n",
    "        if token == '.':\n",
    "            tags.append('O')\n",
    "            continue\n",
    "        span = np.asarray(re.search(token, text_tmp).span())\n",
    "        idx = get_current_annot(annotations, idx, span[0] + offset)\n",
    "        boundaries = annotations[idx]['boundaries']\n",
    "        found = False\n",
    "        for i, (start, end) in enumerate(boundaries):\n",
    "            if (span[0] + offset >= start) and (span[1] + offset <= end):\n",
    "                prefix = 'B-'\n",
    "                if i > 0 or span[0] + offset > start:\n",
    "                    prefix = 'I-'\n",
    "                tags.append(prefix + annotations[idx]['ner'])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            tags.append('O')\n",
    "        offset += span[1]\n",
    "        text_tmp = text_tmp[span[1]:]\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPITOR 86\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m i, med, text, annotations \u001b[38;5;241m=\u001b[39m read_files(fn)\n\u001b[1;32m      5\u001b[0m annots \u001b[38;5;241m=\u001b[39m parse_annotations(annotations)\n\u001b[0;32m----> 6\u001b[0m tokens, tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_IOB_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m med \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      8\u001b[0m     data[med] \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mget_IOB_tags\u001b[0;34m(text, annotations)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m span \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(re\u001b[38;5;241m.\u001b[39msearch(token, text_tmp)\u001b[38;5;241m.\u001b[39mspan())\n\u001b[0;32m---> 14\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mget_current_annot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspan\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m boundaries \u001b[38;5;241m=\u001b[39m annotations[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundaries\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mget_current_annot\u001b[0;34m(annots, idx, start)\u001b[0m\n\u001b[1;32m     32\u001b[0m boundaries \u001b[38;5;241m=\u001b[39m annots[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundaries\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m>\u001b[39m boundaries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_current_annot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m idx\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mget_current_annot\u001b[0;34m(annots, idx, start)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(annots):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 32\u001b[0m boundaries \u001b[38;5;241m=\u001b[39m \u001b[43mannots\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundaries\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m>\u001b[39m boundaries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_current_annot(annots, idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, start)\n",
      "\u001b[0;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for fn in os.listdir(root_txt):\n",
    "    i, med, text, annotations = read_files(fn)\n",
    "    annots = parse_annotations(annotations)\n",
    "    tokens, tags = get_IOB_tags(text, annots)\n",
    "    if med not in data.keys():\n",
    "        data[med] = {}\n",
    "    data[med][i] = {\n",
    "        'tokens': tokens, 'ner': tags\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ADR']\n"
     ]
    }
   ],
   "source": [
    "print(data['LIPITOR'][977]['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tags_tokens(data):\n",
    "    tokens = data['tokens']\n",
    "    tags = data['ner']\n",
    "    line1 = \"\"\n",
    "    line2 = \"\"\n",
    "    for word, label in zip(tokens, tags):\n",
    "        max_length = max(len(word), len(label))\n",
    "        line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "        line2 += label + \" \" * (max_length - len(label) + 1)\n",
    "    print(line1)\n",
    "    print(line2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([86, 92, 952, 946, 45, 775, 761, 51, 79, 991, 749, 985, 588, 577, 211, 205, 563, 239, 403, 365, 371, 417, 359, 198, 826, 832, 167, 601, 615, 173, 629, 628, 614, 172, 166, 600, 833, 199, 827, 358, 370, 416, 402, 364, 238, 204, 562, 576, 210, 589, 984, 78, 748, 990, 760, 50, 44, 774, 947, 953, 93, 87, 91, 979, 85, 945, 789, 951, 52, 762, 776, 46, 986, 992, 560, 206, 212, 574, 548, 399, 414, 372, 366, 400, 428, 819, 831, 825, 170, 616, 602, 164, 158, 159, 603, 165, 171, 617, 824, 830, 818, 429, 367, 401, 415, 373, 398, 549, 213, 575, 561, 207, 993, 987, 777, 47, 53, 763, 950, 788, 944, 84, 90, 978, 798, 940, 954, 94, 80, 968, 983, 997, 767, 57, 43, 773, 559, 203, 565, 571, 217, 388, 439, 377, 411, 405, 363, 834, 820, 808, 149, 613, 175, 161, 607, 160, 606, 612, 174, 148, 809, 821, 835, 404, 362, 376, 410, 438, 389, 570, 216, 202, 564, 558, 42, 772, 766, 56, 996, 982, 81, 969, 95, 955, 1000, 941, 799, 957, 943, 83, 97, 994, 68, 980, 758, 770, 40, 54, 764, 599, 228, 214, 9, 572, 566, 200, 348, 360, 406, 412, 374, 823, 189, 837, 638, 604, 162, 176, 610, 177, 611, 605, 163, 639, 188, 836, 822, 413, 375, 361, 407, 349, 567, 201, 215, 573, 8, 229, 598, 55, 765, 771, 41, 69, 759, 981, 995, 96, 82, 942, 956, 919, 931, 925, 716, 26, 32, 702, 299, 272, 514, 500, 266, 528, 306, 460, 474, 312, 448, 879, 845, 851, 689, 662, 104, 110, 676, 886, 138, 892, 893, 887, 139, 111, 677, 663, 105, 688, 850, 844, 878, 449, 475, 313, 307, 461, 529, 501, 267, 273, 515, 298, 33, 703, 717, 27, 924, 930, 918, 926, 932, 701, 31, 25, 715, 19, 729, 265, 503, 517, 271, 259, 488, 311, 477, 463, 305, 339, 852, 846, 675, 113, 107, 661, 649, 891, 885, 884, 890, 648, 106, 660, 674, 112, 847, 853, 338, 462, 304, 310, 476, 489, 258, 516, 270, 264, 502, 18, 728, 24, 714, 700, 30, 933, 927, 923, 937, 738, 34, 704, 710, 20, 248, 506, 260, 274, 512, 499, 328, 472, 314, 300, 466, 857, 843, 894, 658, 880, 116, 670, 664, 102, 665, 103, 117, 671, 881, 659, 895, 842, 856, 301, 467, 473, 315, 329, 498, 275, 513, 507, 261, 249, 711, 21, 35, 705, 739, 936, 922, 934, 920, 908, 23, 713, 707, 37, 288, 539, 511, 277, 263, 505, 459, 465, 303, 317, 471, 840, 698, 854, 868, 883, 897, 129, 101, 667, 673, 115, 672, 114, 100, 666, 896, 128, 882, 869, 855, 699, 841, 316, 470, 464, 302, 458, 262, 504, 510, 276, 538, 289, 706, 36, 22, 712, 909, 921, 935, 938, 910, 904, 737, 13, 723, 290, 284, 253, 535, 521, 247, 509, 482, 496, 327, 441, 455, 333, 469, 858, 680, 694, 864, 870, 643, 125, 131, 657, 119, 118, 130, 656, 642, 124, 871, 865, 695, 681, 859, 468, 454, 332, 326, 440, 497, 483, 508, 520, 246, 252, 534, 285, 291, 12, 722, 736, 905, 911, 939, 907, 913, 720, 10, 734, 38, 708, 287, 293, 244, 522, 536, 250, 278, 495, 481, 330, 456, 442, 324, 318, 697, 683, 873, 867, 654, 132, 126, 640, 898, 668, 669, 127, 899, 641, 655, 133, 866, 872, 682, 696, 319, 443, 325, 331, 457, 480, 494, 279, 537, 251, 245, 523, 292, 286, 39, 709, 735, 721, 11, 912, 906, 902, 916, 29, 719, 15, 725, 731, 282, 296, 269, 527, 241, 255, 533, 490, 484, 309, 453, 335, 321, 447, 876, 862, 692, 686, 679, 137, 651, 889, 645, 123, 644, 122, 136, 888, 650, 678, 687, 693, 863, 877, 320, 446, 452, 334, 308, 485, 491, 254, 532, 526, 240, 268, 297, 283, 730, 14, 724, 28, 718, 917, 903, 915, 901, 929, 732, 726, 16, 295, 281, 518, 530, 256, 242, 524, 487, 493, 478, 444, 322, 336, 450, 861, 875, 685, 849, 691, 108, 120, 646, 652, 134, 653, 135, 121, 647, 109, 690, 848, 684, 874, 860, 337, 451, 445, 323, 479, 492, 486, 243, 525, 531, 257, 519, 280, 294, 727, 17, 733, 928, 900, 914, 797, 783, 973, 967, 64, 754, 998, 740, 70, 58, 768, 595, 581, 556, 230, 224, 542, 218, 5, 387, 393, 422, 344, 350, 436, 378, 185, 191, 807, 813, 146, 620, 634, 152, 608, 609, 635, 153, 147, 621, 812, 806, 190, 184, 379, 351, 437, 423, 345, 392, 386, 219, 4, 225, 543, 557, 231, 580, 594, 59, 769, 741, 999, 71, 65, 755, 966, 972, 782, 796, 780, 958, 794, 964, 970, 98, 73, 743, 757, 67, 582, 596, 541, 227, 233, 555, 6, 569, 390, 384, 435, 353, 347, 421, 409, 192, 838, 186, 810, 804, 151, 637, 623, 145, 179, 178, 622, 144, 150, 636, 805, 811, 839, 187, 193, 408, 346, 420, 434, 352, 385, 391, 568, 7, 232, 554, 540, 226, 597, 583, 756, 66, 72, 742, 971, 99, 965, 795, 959, 781, 961, 89, 975, 785, 791, 949, 746, 76, 62, 752, 587, 593, 578, 3, 222, 544, 550, 236, 395, 381, 418, 356, 430, 424, 342, 815, 801, 829, 197, 183, 168, 632, 154, 140, 626, 141, 627, 633, 155, 169, 182, 828, 196, 800, 814, 425, 343, 357, 431, 419, 380, 394, 551, 237, 223, 545, 2, 579, 592, 586, 63, 753, 747, 77, 948, 790, 784, 974, 960, 88, 976, 962, 792, 786, 49, 779, 989, 751, 61, 75, 745, 590, 584, 209, 235, 553, 547, 221, 382, 396, 369, 341, 427, 433, 355, 802, 816, 180, 194, 619, 625, 143, 157, 631, 156, 630, 624, 142, 618, 195, 181, 817, 803, 432, 354, 340, 426, 368, 397, 383, 546, 220, 234, 552, 1, 208, 585, 591, 74, 744, 750, 988, 60, 48, 778, 787, 793, 963, 977])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LIPITOR'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stomach \n",
      "B-ADR   \n"
     ]
    }
   ],
   "source": [
    "print_tags_tokens(data['LIPITOR'][155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['stomach', 'pain', ',', 'dizzy', 'spells', ',', 'hairloss', ',', 'fatigue', ',', 'dry', 'eyes', ',', 'joint', 'pain', '.', 'When', 'I', 'stopped', 'taking', 'Lipitor', ',', 'I', 'was', 'amazed', 'at', 'how', 'much', 'better', 'I', 'began', 'to', 'feel', '.', 'While', 'taking', 'Lipitor', 'I', 'had', 'stomach', 'cramps', 'every', 'day', '.', 'I', 'was', 'tired', ',', 'and', 'could', 'not', 'function', 'normal', '.'], 'ner': ['B-ADR']}\n"
     ]
    }
   ],
   "source": [
    "print(data['LIPITOR'][155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
